{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "\n",
    "Acá es donde se hace el entrenamiento.\n",
    "\n",
    "1. Para cada una de las imágenes que guardamos en nuestra base de datos\n",
    "    1. Se detecta la cara de esta imagen y se guarda almacena en una variable.\n",
    "    2. Se obtiene el identificador de cada persona que agregamos a la base de datos, a partir del nombre del archivo.\n",
    "    3. Se guarda el identificador en otra variable, que será nuestra etiqueta para el entrenamiento.\n",
    "2. Se entrena el modelo\n",
    "\n",
    "Nuevamente la intención no es entrar en detalle ni en la extracción de características ni en el algoritmo de clasificación específico de este ejemplo, sino mostrar de punta a punta como se implementa un sistema de reconocimiento facial, entrenando un clasificador con la base de datos que nosotros mismos creamos.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "# La carpeta donde guardamos nuestras imagenes previamente\n",
    "path = 'dataset'\n",
    "\n",
    "# Inicializaos el detector facial\n",
    "detector = cv2.CascadeClassifier(\"default.xml\")\n",
    "# Inicializaos el reconocedor facial\n",
    "reconocedor = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Buscamso todas imagenes dentro de la carpeta donde esta nuestra base de datos\n",
    "imagePaths = glob.glob(path + \"/*.jpg\")\n",
    "\n",
    "# Creamos las variables donde almacenaremos los datos para entrenar. Las caras y sus etiquetas\n",
    "faceSamples=[]\n",
    "ids = []\n",
    "\n",
    "# Para cada imagen:\n",
    "for imagePath in imagePaths:\n",
    "    # Cargamos la imagen y la convertimos a escala de grises\n",
    "    PIL_img = Image.open(imagePath).convert('L')\n",
    "    img_numpy = np.array(PIL_img,'uint8')\n",
    "    # Obtenemos el id de la cara a partir del nombre del archivo\n",
    "    id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "    # Detectamos las caras\n",
    "    faces = detector.detectMultiScale(img_numpy)\n",
    "    # Para cada cara agregamos a nuestras variables la cara y el id de la cara\n",
    "    for (x,y,w,h) in faces:\n",
    "        faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "        ids.append(id)\n",
    "\n",
    "# Proceso de entrenamiento\n",
    "print(\"\\n Empezando el proceso de entrenamiento. Va a tomar unos segundos, espere por favor...\")\n",
    "reconocedor.train(faceSamples, np.array(ids))\n",
    "\n",
    "# Guardamos el modelo en un archivo\n",
    "reconocedor.write('trainer.yml') # recognizer.save()\n",
    "print(\"\\n Proceso terminado. Se entrenaron {0} cara(s)\".format(len(np.unique(ids))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
