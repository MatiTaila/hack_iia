{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "generar dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiTaila/hack_iia/blob/ia-2003/face_detector/generar_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgJYXcuF8Lu",
        "colab_type": "text"
      },
      "source": [
        "## Montar disco de Google Drive\n",
        "\n",
        "Para proder acceder a datos guardados en su google drive desde un notebook de colab es necesario ejecutar el siguiente código\n",
        "\n",
        "Esto va a ser necesario en todos los notebooks de este curso.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP4GcUk3GA3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IKEKjIDFT0t",
        "colab_type": "text"
      },
      "source": [
        "# Generar Dataset\n",
        "\n",
        "El primer paso en cualquier algoritmo de Machine Learning es preprocesar los datos.\n",
        "\n",
        "En particular para aprendizaje supervisado es importante generar un set de datos de entrenamiento y un set de datos de test para poder validar el desempeño de nuestro algoritmo (En general tambien se usa un tercer set de datos llamado validación).\n",
        "\n",
        "Para generar nuestro set de datos vamos a seguir los siguientes pasos.\n",
        "1. Dividir nuestros datos en un split de 90% training y 10% test.\n",
        "2. Para los datos de training vamos a hacer lo siguiente:\n",
        "    1. Se detecta una cara en cada imagen de training y se guarda en una variable.\n",
        "    2. Se obtiene el identificador de cada persona que agregamos a la base de datos, a partir del nombre de la carpeta en que proviene el archivo.\n",
        "    3. Se utiliza el identificador para guardar los datos de entrenamiento.\n",
        "3. Los datos para Testing se guardan si hacer detección facial.\n",
        "\n",
        "Es una buena práctica hacer shuffle de los datos antes de dividir en training y test pero en este caso vamos a recorrer los archivos secuenciales para que todos tengan el mismo resultado.\n",
        "\n",
        "Para comenzar tambien vamos a visualizar los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGXbGr50FT0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os, glob\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Definimos las carpetas y archivos especificos que vamos a utilizar en el script\n",
        "DATASET_DIR = '/content/drive/My Drive/hack_iia/face_detector/dataset'\n",
        "CASCADE_FILE = '/content/drive/My Drive/hack_iia/face_detector/default.xml'\n",
        "TRAIN_DIR = '/content/drive/My Drive/hack_iia/face_detector/dataset/train'\n",
        "TEST_DIR = '/content/drive/My Drive/hack_iia/face_detector/dataset/test'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOkPa6qbFT0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Funcion para mostrar datos de entrenamiento\n",
        "def show_random_sample(train_dir,count=5):\n",
        "    img_paths = glob.glob(os.path.join(train_dir,\"*.jpg\"))\n",
        "    random_paths = random.sample(img_paths,count)\n",
        "    fig, ax = plt.subplots(1,count, figsize=(20,3))\n",
        "    for idx, random_path in enumerate(random_paths):\n",
        "        img = Image.open(random_path)\n",
        "        ax[idx].imshow(img,cmap='gray')\n",
        "        ax[idx].set_xticks([])\n",
        "        ax[idx].set_yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvpkqubIFT02",
        "colab_type": "text"
      },
      "source": [
        "### Visualización de Datos de entranmiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV_kz19YFT03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SUBJECTS = ['jeniffer', 'brad']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_RFdrL3FT07",
        "colab_type": "text"
      },
      "source": [
        "#### JENNIFER ANISTON "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiMUyZz6FT08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_random_sample(os.path.join(DATASET_DIR,SUBJECTS[0]),5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGdhkw68FT1A",
        "colab_type": "text"
      },
      "source": [
        "#### BRAD PITT ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "end7jhDBFT1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_random_sample(os.path.join(DATASET_DIR,SUBJECTS[1]),5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u6UV18gFT1G",
        "colab_type": "text"
      },
      "source": [
        "### PROCESAMOS LOS DATOS PARA EXTRAER CARAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgqFlRvDFT1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Inicializaos el detector facial\n",
        "detector = cv2.CascadeClassifier(CASCADE_FILE)\n",
        "# Inicializaos el reconocedor facial\n",
        "reconocedor = cv2.face.LBPHFaceRecognizer_create()\n",
        "\n",
        "for subject_count, subject_name in enumerate(SUBJECTS):\n",
        "    # Buscamso todas imagenes dentro de la carpeta donde esta nuestra base de datos\n",
        "    image_paths = glob.glob(os.path.join(DATASET_DIR,subject_name,\"*.jpg\"))\n",
        "    id = subject_count + 1\n",
        "    \n",
        "    # Para cada imagen de entrenamiento:\n",
        "    for img_count, img_path in enumerate(image_paths[:170]):\n",
        "        # Cargamos la imagen y la convertimos a escala de grises\n",
        "        PIL_img = Image.open(img_path).convert('L')\n",
        "        img_numpy = np.array(PIL_img,'uint8')\n",
        "        # Detectamos las caras\n",
        "        faces = detector.detectMultiScale(img_numpy, 1.2, 5,  minSize=(int(0.2*img_numpy.shape[0]), int(0.2*img_numpy.shape[1])))\n",
        "        # Para cada cara agregamos a nuestras variables la cara y el id de la cara\n",
        "        for (x,y,w,h) in faces:\n",
        "            # guardamos la imagen capturada en la carpeta de datos de entrenamiento\n",
        "            cv2.imwrite(TRAIN_DIR + \"/persona.\" + str(id) + '.im' + str(img_count) + \".jpg\", img_numpy[y:y + h, x:x + w])\n",
        "    \n",
        "    # Para cada imagen de testing simplemente copiamos:\n",
        "    for img_count, img_path in enumerate(image_paths[170:]):\n",
        "        image_name = subject_name + str(img_count) + '.jpg'\n",
        "        shutil.copy(img_path, os.path.join(TEST_DIR,image_name))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqGbJPUuFT1K",
        "colab_type": "text"
      },
      "source": [
        "### DATOS PROCESAD0S ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7fO8WpkFT1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_random_sample(TRAIN_DIR, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}